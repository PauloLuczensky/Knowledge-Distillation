## ğŸ“˜ Knowledge Distillation with YOLO for Tomato Leaf Disease Detection

Este repositÃ³rio implementa um pipeline de Knowledge Distillation utilizando YOLOv5 para classificaÃ§Ã£o e detecÃ§Ã£o de doenÃ§as em folhas de tomate.

A ideia central Ã© treinar um modelo Teacher, mais pesado e robusto (YOLOv5x), gerar pseudo-labels e transferir esse conhecimento para um modelo Student, mais leve (YOLOv5n), adequado para uso em dispositivos de borda (edge devices).

### ğŸ“‚ Estrutura do Projeto
```
KNOWLEDGE-DISTILLATION
â”œâ”€â”€ tomato_yolo/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ train/               # imagens de treino
â”‚   â”‚   â”œâ”€â”€ val/                 # imagens de validaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ test/                # imagens de teste
â”‚   â”‚       â”œâ”€â”€ healthy     
â”‚   â”‚       
â”œâ”€â”€ yolov5/                      # implementaÃ§Ã£o do YOLOv5
â”œâ”€â”€ kd_pipeline.py               # script principal do pipeline
â”œâ”€â”€ val.py                       # script auxiliar de validaÃ§Ã£o
â”œâ”€â”€ labels.py                    # script para organizaÃ§Ã£o de labels
â””â”€â”€ LICENSE
```
-----

### âš™ï¸ Pipeline Implementado
1ï¸âƒ£ PreparaÃ§Ã£o do Dataset

- Estrutura organizada em train/, val/ e test/.

- GeraÃ§Ã£o automÃ¡tica do arquivo data.yaml.

2ï¸âƒ£ Treinamento do Modelo Teacher (YOLOv5x)

- Modelo robusto e pesado.

- Treinado por 10 Ã©pocas (ajustÃ¡vel via parÃ¢metro epochs).

3ï¸âƒ£ GeraÃ§Ã£o de Pseudo-labels

- O Teacher gera labels preditas para imagens de treino.

- Labels armazenadas em:

    - tomato_yolo/pseudo_labels/

4ï¸âƒ£ Treinamento do Modelo Student (YOLOv5n)

- Modelo leve e eficiente.

- Treinado utilizando as pseudo-labels.

5ï¸âƒ£ AvaliaÃ§Ã£o e ComparaÃ§Ã£o

- MÃ©tricas principais: Precision, Recall, mAP.

- ComparaÃ§Ã£o de tamanho do modelo e velocidade de inferÃªncia (FPS).

-----------

### ğŸš€ ExecuÃ§Ã£o
1ï¸âƒ£ Clonar o RepositÃ³rio e Instalar DependÃªncias
```
git clone https://github.com/usuario/knowledge-distillation.git
cd knowledge-distillation
pip install -r requirements.txt
```
2ï¸âƒ£ Rodar o Pipeline Completo
```
python kd_pipeline.py
```
3ï¸âƒ£ Estrutura de SaÃ­da

ApÃ³s a execuÃ§Ã£o, vocÃª terÃ¡:

- runs/teacher/ â†’ pesos e logs do YOLOv5x.

- runs/student/ â†’ pesos e logs do YOLOv5n.

ComparaÃ§Ã£o de mÃ©tricas diretamente no terminal.

-------------

### ğŸ“Š Resultados Obtidos (10 Ã‰pocas)

| **MÃ©trica**                  | **Teacher (YOLOv5x)** | **Student (YOLOv5n)** |
|-------------------------------|-----------------------|------------------------|
| **ParÃ¢metros**               | 97M                  | 2.5M                  |
| **GFLOPs**                   | 246.9                | 7.2                    |
| **Tamanho do Modelo**        | ~195 MB              | ~5 MB                  |
| **Tempo de Treino (CPU)**    | ~1h47min             | ~4m30s                 |
| **Precision (P)**            | 0.993                | 0.998                  |
| **Recall (R)**               | 0.969                | 1.000                  |
| **mAP@50**                   | 0.994                | 0.995                  |
| **mAP@50-95**                | 0.901                | 0.995                  |
| **Velocidade de InferÃªncia** | ~1392 ms/imagem      | ~50â€“70 ms/imagem       |


### ğŸ” Insights

- O Teacher Ã© Ãºtil para guiar o treinamento, mas Ã© muito pesado para deploy.

- O Student atingiu mÃ©tricas praticamente iguais com 40x menos parÃ¢metros e 20x mais rÃ¡pido.

- Indicado para aplicaÃ§Ãµes em Edge Computing e ambientes com restriÃ§Ã£o de hardware.

### ğŸ“– ReferÃªncias

[1] YOLOv5 - Ultralytics

[2] Hinton, G., Vinyals, O., & Dean, J. (2015). Distilling the Knowledge in a Neural Network.

[3] Dataset: Tomato Leaf Diseases (adaptado).